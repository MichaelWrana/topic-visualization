{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "499ca1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrends\n",
    "import webbrowser, os\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm.notebook import tqdm\n",
    "from pytrends.request import TrendReq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8f8276c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "term: a length 1 array containing a string to be searched\n",
    "years: an array of strings containing years to be searched\n",
    "'''\n",
    "def get_trends(term, years, pytrends=TrendReq()):\n",
    "    # get results and remove incomplete entries\n",
    "    timeframe = years[0] + '-01-01 ' + years[-1] + '-12-31'\n",
    "    \n",
    "    # get dataframe and re-format to numpy\n",
    "    pytrends.build_payload(term, timeframe=timeframe)\n",
    "    df = pytrends.interest_over_time()\n",
    "    df = df.drop(df[df.isPartial].index)\n",
    "    np_data = df.drop('isPartial', axis=1).to_numpy()\n",
    "    \n",
    "    # wait 5 seconds so google doesnt block me\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # split the data into years, and get the max of each year\n",
    "    # basically, return an array with the highest trend score in that year\n",
    "    \n",
    "    return [np.amax(x.flatten()) for x in np.split(np_data,len(years))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8773aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "term: a length 1 array containing a string to be searched\n",
    "years: an array of strings containing years to be searched\n",
    "'''\n",
    "def get_dblp(term, years):\n",
    "    # setup query variables and result array\n",
    "    api_base = 'https://dblp.org/search/publ/api'\n",
    "    result = []\n",
    "    \n",
    "    search_term = '?q=' + term[0].replace(' ', '+') + '+'\n",
    "    term_result = []\n",
    "    \n",
    "    for year in years:\n",
    "        year_term = 'year:' + year + ':'\n",
    "        # make request and extract total number of hits\n",
    "        html = requests.get(api_base + search_term + year_term).text\n",
    "        result.append(ET.fromstring(html).find('./hits').attrib['total'])\n",
    "        \n",
    "    \n",
    "    # conver to integer and normalize on 1-100 (like google trends)\n",
    "    result = [int(i) for i in result]\n",
    "    max_r = max(result)\n",
    "    normalized_result = [round(i/max_r * 100) for i in result]\n",
    "    return normalized_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e95cc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(terms, years):\n",
    "    # setup variables\n",
    "    trends_res = []\n",
    "    dblp_res = []\n",
    "    \n",
    "    # make API/Scrape requests, and collect in array\n",
    "    for term in tqdm(terms): \n",
    "        trends_res.append(get_trends(term, years))\n",
    "        dblp_res.append(get_dblp(term, years))\n",
    "    return trends_res, dblp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ab396227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04374d9e88344180a8857ef8a5501495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "terms = [['machine learning'],['artificial intelligence']]\n",
    "years=[str(2010+i) for i in range(11)]\n",
    "\n",
    "trends_data, dblp_data = scrape_data(terms, years)\n",
    "difference = np.subtract(trends_data, dblp_data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "716cda2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 12, 12, 14, 18, 28, 46, 80, 91, 97, 100], [36, 44, 35, 32, 38, 40, 53, 95, 100, 97, 95]]\n",
      "[[20, 8, 10, 11, 14, 18, 24, 47, 53, 79, 100], [17, 17, 17, 20, 18, 19, 19, 24, 41, 68, 100]]\n"
     ]
    }
   ],
   "source": [
    "print(trends_data)\n",
    "print(dblp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9f510021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart1_dataset(i):\n",
    "    trends_dset = {\n",
    "        'label': \"Google Trends\",\n",
    "        'data': [int(x) for x in trends_data[i]],\n",
    "        'borderColor': 'rgba(255,0,0,1)',\n",
    "        'backgroundColor': 'rgba(255,0,0,0.5)',\n",
    "        'fill': True\n",
    "    }\n",
    "    dblp_dset = {\n",
    "        'label': \"DBLP\",\n",
    "        'data': [int(x) for x in dblp_data[i]],\n",
    "        'borderColor': 'rgba(0,0,255,1)',\n",
    "        'backgroundColor': 'rgba(0,0,255,0.5)',\n",
    "        'fill': True\n",
    "    } \n",
    "    return [trends_dset, dblp_dset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "f992a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart1 = []\n",
    "i=0\n",
    "\n",
    "for term in terms:\n",
    "    data = {\n",
    "        'name': term[0],\n",
    "        'labels': years,\n",
    "        'datasets': get_chart1_dataset(i)\n",
    "    }\n",
    "    chart1.append(data)\n",
    "    i+=1\n",
    "    \n",
    "import json\n",
    "\n",
    "with open('html/data.js', 'w', encoding='utf-8') as f:\n",
    "    f.write('const data_c1 = ')\n",
    "    json.dump(chart1, f, ensure_ascii=False, indent=4)\n",
    "    f.write(';\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3c7d5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2 = []\n",
    "i=0\n",
    "\n",
    "for term in terms:\n",
    "    data = {\n",
    "        'name': term[0],\n",
    "        'labels': years,\n",
    "        'datasets': [{\n",
    "            'label': term[0],\n",
    "            'data': [int(x) for x in difference[i]],\n",
    "            'borderColor': 'rgba(255,0,255,1)',\n",
    "            'backgroundColor': 'rgba(255,0,255,0.5)',\n",
    "            'fill': {\n",
    "                'above': 'blue',\n",
    "                'below': 'red',\n",
    "                'target': {'value': 0},\n",
    "            },\n",
    "        }],\n",
    "    }\n",
    "    chart2.append(data)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "3ad39dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('html/data.js', 'a', encoding='utf-8') as f:\n",
    "    f.write('const data_c2 = ')\n",
    "    json.dump(chart2, f, ensure_ascii=False, indent=4)\n",
    "    f.write(';\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "830a6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score = np.add(trends_data, dblp_data).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "346685fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chart3_dataset():\n",
    "    colors = ['#301A4B', '#6DB1BF', '#FFEAEC', '#F39A9D', '#3F6C51']\n",
    "    datasets = []\n",
    "    i=0\n",
    "    for term in terms:\n",
    "        dataset = {\n",
    "            'label': term[0],\n",
    "            'data': [int(x) for x in sum_score[i]],\n",
    "            'backgroundColor': colors[i % (len(colors)-1)],\n",
    "        }\n",
    "        i+=1\n",
    "        datasets.append(dataset)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "31762569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chart3 = []\n",
    "\n",
    "data = {\n",
    "    'name': term[0],\n",
    "    'labels': years,\n",
    "    'datasets': get_chart3_dataset()\n",
    "}\n",
    "chart3.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e3d94715",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('html/data.js', 'a', encoding='utf-8') as f:\n",
    "    f.write('const data_c3 = ')\n",
    "    json.dump(chart3, f, ensure_ascii=False, indent=4)\n",
    "    f.write(';\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8ef17b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate array to be 2017: trends, dblp\n",
    "trends_data_yearly = np.swapaxes(trends_data, 0, 1)\n",
    "dblp_data_yearly = np.swapaxes(dblp_data, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d440a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
